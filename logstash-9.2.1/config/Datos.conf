input {
  # Lectura del archivo .ndjson
  file {
    path => "/home/g6/reto/datos/steam-games-data-vect.ndjson"
    start_position => "beginning"
    # El uso de sincedb_path => "/dev/null" es correcto para reingestar siempre desde el inicio
    sincedb_path => "/dev/null"
    # Especificamos el codec para asegurar que cada línea se trata como un JSON
    codec => json
  }
}

filter {
  # NOTA: Ya no es necesario el filtro 'json { source => "message" }'
  # porque se usó 'codec => json' en el input.
  
  # --- 1. Arreglo CRÍTICO de fecha (release_date) ---
  if [release_date] {
    date {
      match => [ "release_date", "yyyy-MM-dd" ]
      target => "release_date"
      timezone => "UTC"
    }
  }

  # --- 2. Uso OBLIGATORIO de GROK: Extracción de Requisitos Mínimos del PC ---
  # El patrón GROK debe ser más robusto para capturar los datos que no están
  # en un formato estricto de clave-valor y manejar el campo pc_requirements_min
  # que a veces no sigue un patrón simple.
  
  # Patrón más adaptable:
  grok {
    match => { 
      "pc_requirements_min" => [
        # Intenta capturar un patrón más completo, que es común
        "SO: .*?%{DATA:min_os}\. Procesador: %{DATA:min_cpu}\. Memoria: .*?%{NUMBER:min_ram_gb:int} GB de RAM Gráficos: .*?%{DATA:min_gpu} DirectX: .*?%{DATA:min_directx}.*",
        # Patrón para los que no tienen el SO
        "Procesador: .*?%{DATA:min_cpu} Memoria: .*?%{NUMBER:min_ram_gb:int} GB de RAM Gráficos: .*?%{DATA:min_gpu} DirectX: .*?%{DATA:min_directx}.*"
      ]
    }
    tag_on_failure => [ "grok_pc_fail" ]
    # Quita el campo original si el parseo tiene éxito (opcional, para limpieza)
    remove_field => ["pc_requirements_min"] 
  }

  # --- 3. Conversión de tipos y limpieza de datos (Mutate) ---
  mutate {
    # Convertir campos numéricos y booleanos.
    convert => {
      "price_eur"          => "float"
      "price_initial_eur"  => "float"
      "discount_pct"       => "integer"
      "metacritic_score"   => "integer"
      "recommendations_total" => "integer"
      "achievements_count" => "integer"
      "is_free"            => "boolean"
      "steam_id"           => "integer"
      # Asegurar que los campos extraídos con GROK son del tipo correcto
      "min_ram_gb"         => "integer"
      "vector_embedding" => "float" 
    }
    
    # Renombrar campos clave (como en tu config original)
    rename => {
      "steam_id"  => "appid"
      "price_eur" => "price_final"
    }
    
    # Limpieza final de campos no necesarios (como en tu config original)
    remove_field => [
      "message",
      "@version",
      "host",
      "path",
      "type",
      "tags", 
      "event",
      # También eliminamos el campo 'message' que ahora es el JSON completo,
      # ya que sus contenidos se han movido a campos individuales
      "message" 
    ]
  }

  # --- 4. Categorización por precio (Ruby - Como en tu config original) ---
  ruby {
    code => '
      price = event.get("price_final")
      is_free = event.get("is_free")

      if is_free == true || (price && price == 0)
        event.set("price_category", "Gratis")
      elsif price && price < 15.0
        event.set("price_category", "Barato")
      elsif price && price < 40.0
        event.set("price_category", "Normal")
      else
        event.set("price_category", "Premium")
      end
    '
  }
  
  # --- 5. Adición del campo de actualización (para uso en Kibana/BI) ---
  # Esto cumple el objetivo de tener información para visualización y análisis de datos [cite: 521, 568]
  mutate {
    add_field => { "last_updated" => "%{@timestamp}" }
  }
  
  date {
    match => ["last_updated", "ISO8601"]
    target => "last_updated"
  }
}

output {
  # --- Output a Elasticsearch con Índice DINÁMICO DIARIO ---
  # Esto cumple el requisito de que el índice del log de scraping se tiene que 
  # actualizar con una variable dinámica que se actualice cada día.
  elasticsearch {
    index => "steam_games-%{+yyyy.MM.dd}" # Índice DINÁMICO REQUERIDO
    hosts => ["https://192.199.1.53:9200", "https://192.199.1.65:9200", "https://192.199.1.66:9200"]
    # Uso de API Key para acceso, cumpliendo el requisito de seguridad [cite: 557, 559]
    api_key => "hqQJypoBqiFKKsx-mbaD:mZRPaYKSOrm7CpnWEDJ2xg"
    
    # Configuración SSL/TLS
    ssl_certificate_authorities => ["/home/g6/reto/elasticsearch-9.2.1/config/certs/http_ca.crt"]
    ssl_verification_mode => "full"
    
    # Usar el appid como document_id para evitar duplicados en el reingreso (idempotencia)
    document_id => "%{appid}"
  }
  
  # Opcional: Salida para debug si necesitas verificar los datos antes de ELS
  # stdout {
  #   codec => rubydebug
  # }
}