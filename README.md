# üéÆ Steam Big Data Infrastructure

Este proyecto implementa una infraestructura completa de Big Data para el an√°lisis de datos de videojuegos de Steam, utilizando el stack ELK (Elasticsearch, Logstash, Kibana) con un cl√∫ster distribuido de 3 nodos.

## üìÅ Estructura del Proyecto

```
/home/g6/reto/
‚îú‚îÄ‚îÄ datos/                          # Datos fuente y logs
‚îÇ   ‚îú‚îÄ‚îÄ steam-games-data-vect.ndjson    # Dataset principal de juegos Steam
‚îÇ   ‚îî‚îÄ‚îÄ scraper_metrics.log             # Logs del proceso de scraping
‚îÇ
‚îú‚îÄ‚îÄ elasticsearch-9.2.1/            # Nodo de Elasticsearch
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îú‚îÄ‚îÄ elasticsearch.yml           # Configuraci√≥n del cl√∫ster
‚îÇ       ‚îî‚îÄ‚îÄ certs/                      # Certificados SSL/TLS
‚îÇ           ‚îú‚îÄ‚îÄ http.p12
‚îÇ           ‚îú‚îÄ‚îÄ transport.p12
‚îÇ           ‚îî‚îÄ‚îÄ http_ca.crt
‚îÇ
‚îú‚îÄ‚îÄ logstash-9.2.1/                 # Pipeline de procesamiento
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îú‚îÄ‚îÄ Datos.conf                  # Pipeline para datos de juegos
‚îÇ       ‚îú‚îÄ‚îÄ Logs.conf                   # Pipeline para logs de scraping
‚îÇ       ‚îî‚îÄ‚îÄ pipelines.yml               # Configuraci√≥n de pipelines
‚îÇ
‚îî‚îÄ‚îÄ metricbeat-9.2.1/               # Monitoreo de m√©tricas
    ‚îî‚îÄ‚îÄ config/
        ‚îî‚îÄ‚îÄ metricbeat.yml
```

---

## üîó Flujo de Datos: C√≥mo se Complementan las Carpetas

### 1Ô∏è‚É£ **`/reto/datos` - Origen de los Datos**

**Contenido:**
- `steam-games-data-vect.ndjson`: Archivo NDJSON con informaci√≥n de ~86,000 juegos de Steam
  - Datos: nombre, precio, g√©neros, requisitos PC, embeddings vectoriales
  - Formato: Una l√≠nea JSON por juego
  
- `scraper_metrics.log`: Logs generados durante el scraping de la API de Steam
  - M√©tricas: latencia de API, c√≥digos HTTP, offsets, errores

**Prop√≥sito:**
- Act√∫a como la **fuente de verdad** del sistema
- Datos persistentes que se ingestan y procesan

---

### 2Ô∏è‚É£ **`/reto/logstash-9.2.1/config` - Pipeline de Transformaci√≥n**

#### **Archivo: `Datos.conf`** 
**Pipeline de Datos de Juegos ‚Üí Elasticsearch**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ INPUT: Lee steam-games-data-vect.ndjson                    ‚îÇ
‚îÇ   - Lectura l√≠nea por l√≠nea con codec JSON                 ‚îÇ
‚îÇ   - sincedb_path => "/dev/null" (reingestar desde inicio)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FILTER: Transformaci√≥n de Datos                            ‚îÇ
‚îÇ   1. Date parsing: release_date ‚Üí formato Elasticsearch    ‚îÇ
‚îÇ   2. GROK: Extrae requisitos PC (SO, CPU, RAM, GPU)        ‚îÇ
‚îÇ   3. Mutate: Conversiones de tipos (float, int, boolean)   ‚îÇ
‚îÇ   4. Ruby: Categoriza precios (Gratis/Barato/Normal/Premium)‚îÇ
‚îÇ   5. A√±ade timestamp de √∫ltima actualizaci√≥n               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OUTPUT: Elasticsearch Cl√∫ster (3 nodos)                    ‚îÇ
‚îÇ   - √çndice din√°mico: steam_games-YYYY.MM.DD                ‚îÇ
‚îÇ   - Hosts: 192.199.1.53, 192.199.1.65, 192.199.1.66        ‚îÇ
‚îÇ   - Autenticaci√≥n: API Key                                 ‚îÇ
‚îÇ   - SSL/TLS con certificado CA                             ‚îÇ
‚îÇ   - Document ID: appid (evita duplicados)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caracter√≠sticas clave:**
- ‚úÖ **Idempotencia**: Usa `appid` como ID √∫nico
- ‚úÖ **√çndice diario rotativo**: Facilita la gesti√≥n de datos hist√≥ricos
- ‚úÖ **Enriquecimiento**: Extrae metadata de requisitos PC y Datos de el .log con GROK
- ‚úÖ **Seguridad**: Conexi√≥n HTTPS con validaci√≥n completa de certificados

---

#### **Archivo: `Logs.conf`**
**Pipeline de Logs de Scraping ‚Üí Elasticsearch**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ INPUT: Lee scraper_metrics.log                             ‚îÇ
‚îÇ   - Tag: "scraper_metrics"                                 ‚îÇ
‚îÇ   - Monitoreo continuo del archivo                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FILTER: Parsing Estructurado de Logs                       ‚îÇ
‚îÇ   1. GROK: Extrae timestamp, log_level, mensaje            ‚îÇ
‚îÇ   2. Condicional por nivel:                                ‚îÇ
‚îÇ      - INFO: Extrae URL, status HTTP, latency, offset      ‚îÇ
‚îÇ      - ERROR: Extrae tipo de error, URL fallida, detalles  ‚îÇ
‚îÇ   3. Date parsing: Convierte timestamp a @timestamp        ‚îÇ
‚îÇ   4. Limpieza de campos intermedios                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OUTPUT: Elasticsearch Cl√∫ster                              ‚îÇ
‚îÇ   - √çndice din√°mico: scraper_logs-YYYY.MM.DD               ‚îÇ
‚îÇ   - Misma configuraci√≥n SSL/TLS que Datos.conf             ‚îÇ
‚îÇ   - Debug: stdout con rubydebug                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Caracter√≠sticas clave:**
- ‚úÖ **Observabilidad**: Monitoreo de rendimiento del scraper
- ‚úÖ **Trazabilidad**: Cada petici√≥n HTTP registrada
- ‚úÖ **Alertas**: Detecta errores y timeouts

---

### 3Ô∏è‚É£ **`/reto/elasticsearch-9.2.1/config` - Almacenamiento y B√∫squeda**

#### **Archivo: `elasticsearch.yml`**

**Configuraci√≥n del Cl√∫ster:**

```yaml
cluster.name: chatbot-cluster          # Cl√∫ster unificado de 3 nodos
node.name: node-2                      # Identificador del nodo
node.roles: [master, data, ingest]     # Nodo completo (todos los roles)

# Red
network.host: 0.0.0.0                  # Escucha en todas las interfaces
discovery.seed_hosts:                  # IPs de los otros nodos
  - 192.199.1.53:9300
  - 192.199.1.65:9300
  - 192.199.1.66:9300

# Seguridad (HTTPS + Autenticaci√≥n)
xpack.security.enabled: true
xpack.security.http.ssl:
  enabled: true
  keystore.path: certs/http.p12        # Certificado HTTPS
  
xpack.security.transport.ssl:
  enabled: true
  verification_mode: certificate       # Verificaci√≥n mutua TLS
  keystore.path: certs/transport.p12   # Certificado inter-nodos
  truststore.path: certs/transport.p12
```

**Caracter√≠sticas del Cl√∫ster:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CL√öSTER: chatbot-cluster                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Nodo 1 (192.199.1.53)    Nodo 2 (192.199.1.65)           ‚îÇ
‚îÇ  Nodo 3 (192.199.1.66)                                     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚úÖ Alta Disponibilidad: Tolerancia a fallos (2/3 activos) ‚îÇ
‚îÇ  ‚úÖ Balanceo de Carga: Logstash distribuye entre 3 nodos   ‚îÇ
‚îÇ  ‚úÖ Replicaci√≥n: Shards duplicados entre nodos            ‚îÇ
‚îÇ  ‚úÖ Seguridad: TLS + API Keys + RBAC                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Flujo Completo de Extremo a Extremo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Steam API        ‚îÇ
‚îÇ  (Scraper)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ Genera
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  /reto/datos/                                             ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ steam-games-data-vect.ndjson  (86K juegos)          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ scraper_metrics.log           (logs de scraping)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                              ‚îÇ
         ‚îÇ Lee                          ‚îÇ Lee
         ‚Üì                              ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Logstash Pipeline    ‚îÇ    ‚îÇ  Logstash Pipeline    ‚îÇ
‚îÇ  Datos.conf           ‚îÇ    ‚îÇ  Logs.conf            ‚îÇ
‚îÇ  ‚îú‚îÄ Parse JSON        ‚îÇ    ‚îÇ  ‚îú‚îÄ Parse logs        ‚îÇ
‚îÇ  ‚îú‚îÄ GROK requisitos   ‚îÇ    ‚îÇ  ‚îú‚îÄ GROK m√©tricas     ‚îÇ
‚îÇ  ‚îú‚îÄ Categoriza precio ‚îÇ    ‚îÇ  ‚îî‚îÄ Extrae errores    ‚îÇ
‚îÇ  ‚îî‚îÄ Valida tipos      ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
            ‚îÇ                            ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Env√≠a (HTTPS)
                         ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Elasticsearch Cl√∫ster (3 nodos)  ‚îÇ
        ‚îÇ   ‚îú‚îÄ node-1 (192.199.1.53)         ‚îÇ
        ‚îÇ   ‚îú‚îÄ node-2 (192.199.1.65)         ‚îÇ
        ‚îÇ   ‚îî‚îÄ node-3 (192.199.1.66)         ‚îÇ
        ‚îÇ                                    ‚îÇ
        ‚îÇ   √çndices creados:                 ‚îÇ
        ‚îÇ   ‚îú‚îÄ steam_games-2025.12.02       ‚îÇ
        ‚îÇ   ‚îî‚îÄ scraper_logs-2025.12.02      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ Consultas
                    ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  Kibana / Visualizaci√≥n‚îÇ
        ‚îÇ  - Dashboards          ‚îÇ
        ‚îÇ  - B√∫squedas           ‚îÇ
        ‚îÇ  - Alertas             ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è Gesti√≥n del Sistema

### Iniciar Servicios

```bash
# Elasticsearch (en cada nodo)
/home/g6/reto/elasticsearch-9.2.1/bin/elasticsearch -d

# Logstash (como servicio systemd)
sudo systemctl start logstash
sudo systemctl enable logstash  # Auto-inicio en boot

# Verificar estado
sudo systemctl status logstash
```

### Monitoreo

```bash
# Estado del cl√∫ster
curl -k -H "Authorization: ApiKey $(echo -n 'API_ID:API_KEY' | base64)" \
  https://192.199.1.53:9200/_cluster/health?pretty

# Ver √≠ndices creados
curl -k -H "Authorization: ApiKey $(echo -n 'API_ID:API_KEY' | base64)" \
  https://192.199.1.53:9200/_cat/indices?v

# Logs de Logstash en tiempo real
sudo journalctl -u logstash -f
```

### Reingesta de Datos

```bash
# Detener Logstash
sudo systemctl stop logstash

# Eliminar √≠ndice (si es necesario)
curl -X DELETE "https://192.199.1.53:9200/steam_games-*" \
  -H "Authorization: ApiKey ..."

# Reiniciar Logstash (reingestar√° autom√°ticamente)
sudo systemctl start logstash
```

---

## üîê Seguridad Implementada

| Capa | Mecanismo | Ubicaci√≥n |
|------|-----------|-----------|
| **Transporte** | TLS mutuo | `elasticsearch-9.2.1/config/certs/transport.p12` |
| **HTTP/API** | HTTPS | `elasticsearch-9.2.1/config/certs/http.p12` |
| **Autenticaci√≥n** | API Keys | Configurados en Datos.conf y Logs.conf |
| **Autorizaci√≥n** | RBAC | Permisos por API Key |
| **Validaci√≥n** | Certificate Authority | `certs/http_ca.crt` |

---

## üìä √çndices y Esquemas

### `steam_games-YYYY.MM.DD`
**Campos principales:**
- `appid` (integer): ID √∫nico del juego
- `name` (text): Nombre del juego
- `price_final` (float): Precio actual
- `price_category` (keyword): Gratis/Barato/Normal/Premium
- `release_date` (date): Fecha de lanzamiento
- `min_ram_gb`, `min_cpu`, `min_gpu`: Requisitos PC
- `vector_embedding` (dense_vector): Para b√∫squedas sem√°nticas

### `scraper_logs-YYYY.MM.DD`
**Campos principales:**
- `@timestamp` (date): Momento del log
- `log_level` (keyword): INFO/ERROR/WARNING
- `request_url` (text): URL de la API consultada
- `http_status` (integer): C√≥digo de respuesta HTTP
- `api_latency` (float): Tiempo de respuesta en segundos
- `error_type`, `error_details`: Informaci√≥n de errores

---

**Documentaci√≥n creada:** Diciembre 2025  
**Versi√≥n Stack ELK:** 9.2.1  
**Proyecto:** Steam Big Data Infrastructure

# Para ¬°¬°¬°VALIDACION!!!

**Usar estos comandos para descargar elastic y logstash**

```bash

# Elasticsearch 9.2.1

wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-9.2.2-linux-x86_64.tar.gz
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-9.2.2-linux-x86_64.tar.gz.sha512
shasum -a 512 -c elasticsearch-9.2.2-linux-x86_64.tar.gz.sha512
tar -xzf elasticsearch-9.2.2-linux-x86_64.tar.gz
cd elasticsearch-9.2.2/

# Logstash 9.2.1
wget https://artifacts.elastic.co/downloads/logstash/logstash-9.2.2-linux-x86_64.tar.gz
wget https://artifacts.elastic.co/downloads/logstash/logstash-9.2.2-linux-x86_64.tar.gz.sha512
shasum -a 512 -c logstash-9.2.2-linux-x86_64.tar.gz.sha512
tar -xzf logstash-9.2.2-linux-x86_64.tar.gz
cd logstash-9.2.2/

# Iniciar elastic
bin/elasticsearch

```

**Copiar a un block de notas la pasword de elastic**

**entrar logsatsh, crear el datos.conf y pegar esto dentro**

```yaml

input {
  # Lectura del archivo .ndjson
  file {
    path => "/home/lander/valReto/scraper/data_output/steam-games-data-vect.ndjson"  <----- Cambiar el path al archivo real
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => json
  }
}

filter {
  # --- 1. Procesamiento de fechas ---
  if [release_date] {
    date {
      match => [ "release_date", "yyyy-MM-dd" ]
      target => "release_date"
      timezone => "UTC"
    }
  }

  # --- 2. Grok para extraer requisitos m√≠nimos de PC ---
  
  grok {
    match => { 
      "pc_requirements_min" => [
        # Intenta capturar un patr√≥n m√°s completo, que es com√∫n
        "SO: .*?%{DATA:min_os}\. Procesador: %{DATA:min_cpu}\. Memoria: .*?%{NUMBER:min_ram_gb:int} GB de RAM Gr√°ficos: .*?%{DATA:min_gpu} DirectX: .*?%{DATA:min_directx}.*",
        # Patr√≥n para los que no tienen el SO
        "Procesador: .*?%{DATA:min_cpu} Memoria: .*?%{NUMBER:min_ram_gb:int} GB de RAM Gr√°ficos: .*?%{DATA:min_gpu} DirectX: .*?%{DATA:min_directx}.*"
      ]
    }
    tag_on_failure => [ "grok_pc_fail" ]
    remove_field => ["pc_requirements_min"] 
  }

  mutate {
    # Convertir campos num√©ricos y booleanos.
    convert => {
      "price_eur"          => "float"
      "price_initial_eur"  => "float"
      "discount_pct"       => "integer"
      "metacritic_score"   => "integer"
      "recommendations_total" => "integer"
      "achievements_count" => "integer"
      "is_free"            => "boolean"
      "steam_id"           => "integer"
      "min_ram_gb"         => "integer"
      "vector_embedding" => "float" 
    }
    

    rename => {
      "steam_id"  => "appid"
      "price_eur" => "price_final"
    }
    
    # Limpieza final de campos no necesarios 
    remove_field => [
      "message",
      "@version",
      "host",
      "path",
      "type",
      "tags", 
      "event",
      "message" 
    ]
  }

  ruby {
    code => '
      price = event.get("price_final")
      is_free = event.get("is_free")

      if is_free == true || (price && price == 0)
        event.set("price_category", "Gratis")
      elsif price && price < 15.0
        event.set("price_category", "Barato")
      elsif price && price < 40.0
        event.set("price_category", "Normal")
      else
        event.set("price_category", "Premium")
      end
    '
  }

  mutate {
    add_field => { "last_updated" => "%{@timestamp}" }
  }
  
  date {
    match => ["last_updated", "ISO8601"]
    target => "last_updated"
  }
}

output {
  elasticsearch {
    index => "steam_games-%{+yyyy.MM.dd}" 
    
    # CORRECCI√ìN 1: Faltaban las barras // despu√©s de https:
    hosts => ["https://localhost:9200"]
    
    # CORRECCI√ìN 2: Cambio de API Key a Usuario/Pass
    user => "elastic"
    password => "A2*dwvdR4O4BDc6DN_a4"  <----- Cambiar a la contrase√±a de elastic
    
    # Configuraci√≥n SSL/TLS
    ssl_certificate_authorities => ["/home/lander/valReto/elasticsearch-9.2.2/config/certs/http_ca.crt"]    <----- Cambiar el path al archivo real del certificado
    
    # Si te da errores de certificado en local, puedes cambiar esto a "none" temporalmente
    ssl_verification_mode => "full" 
    
    document_id => "%{appid}"
    
    # Evita duplicados o problemas si el documento ya existe
    action => "update"
    doc_as_upsert => true
  }
  
  # Descomenta esto si quieres ver por pantalla qu√© est√° pasando
  stdout { codec => rubydebug }
}

```

**Ejecutar este comando en la TERMINAL de ELASTIC para generar el mapping**

Cambiar esto por la contrase√±a de elastic: (elastic:A2*dwvdR4O4BDc6DN_a4 <---- Esto)

```bash

curl -k -u elastic:A2*dwvdR4O4BDc6DN_a4 \ 
-X PUT "https://localhost:9200/_index_template/steam_games_template" \
-H 'Content-Type: application/json' \
-d'
{
  "index_patterns": ["steam_games-*"],
  "template": {
    "mappings": {
      "properties": {
        "vector_embedding": {
          "type": "dense_vector",
          "dims": 768,
          "index": true,
          "similarity": "cosine"
        },
        "price_final": { "type": "float" },
        "release_date": { "type": "date" },
        "name": { "type": "text", "analyzer": "standard" },
        "detailed_description": { "type": "text", "analyzer": "spanish" }
      }
    }
  }
}
'

```

**Iniciar logastash en su terminal**

Poner el path de el datos.conf aqui ---> (config/datos.conf)

```bash

bin/logastash -f config/datos.conf

```


**Por ultimo comprobar que se han subido los datos**

Cambiar la contrase√±a de elastic aqui ---> (elastic:A2*dwvdR4O4BDc6DN_a4)

```bash

curl -k -u elastic:A2*dwvdR4O4BDc6DN_a4 -X GET "https://localhost:9200/_cat/indices/steam_games-*?v"

```


